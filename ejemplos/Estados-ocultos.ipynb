{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRJN0gAWnOOL"
      },
      "source": [
        "<center>\n",
        "<p><img src=\"https://mcd.unison.mx/wp-content/themes/awaken/img/logo_mcd.png\" width=\"150\">\n",
        "</p>\n",
        "\n",
        "\n",
        "\n",
        "<h1>Redes Neuronales Recurrentes (RNN) con numpy</h1>\n",
        "\n",
        "<h3>Curso Aprendizaje Automático Aplicado</h3>\n",
        "\n",
        "\n",
        "<p> Julio Waissman Vilanova </p>\n",
        "\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/mcd-unison/pln/blob/main/labs/RNN/Estados-ocultos.ipynb\"><img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\"  width=\"30\" /> Ejecuta en Colab</a>\n",
        "\n",
        "<p>\n",
        "Tomado parcialmente y adaptado de libretas de la <i>Especialización en procesamiento de lenguaje natural</i> de <i>Deeplearning.ai</i>, disponible en <i>Coursera</i>.\n",
        "</p>\n",
        "\n",
        "\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKnPu1hlnOOR"
      },
      "source": [
        "## RNN vainilla\n",
        "\n",
        "Para una RNN simple como se muestra en la figura:\n",
        "\n",
        "![vanilla rnn](https://github.com/mcd-unison/aaa-curso/blob/main/ejemplos/vanilla_rnn.PNG?raw=1)\n",
        "\n",
        "\n",
        "La activación de los estados ocultos están dados por:      \n",
        "\n",
        "$h^{<t>}=g(W_{hh}h^{<t-1>} + W_{hx}x^{<t>} + b_h)$                                        \n",
        "\n",
        "\n",
        "este ejemplo lo vams a hacer usando exclusivamente `numpy` para entender el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-R31XSR0nOOT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from time import perf_counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbLiJgthnOOU"
      },
      "source": [
        "Vamos entonces a desarrollar la función de alimentación a adelante de una RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JStXw7FknOOV"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    # Calcula la función logística\n",
        "\n",
        "    ## INICIA CODIGO\n",
        "    return 1/(1+np.exp(x))\n",
        "    ## ACABA CODIGO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4Xfa95bsnOOV"
      },
      "outputs": [],
      "source": [
        "    def forward_V_RNN(inputs, weights):\n",
        "        # Forward propagation para una RNN vanilla\n",
        "        x_t, h_t_prev = inputs\n",
        "\n",
        "        # weights.\n",
        "        w_hh, w_xh, b_h = weights\n",
        "\n",
        "        ### INICIA CODIGO ###\n",
        "        # Nuevo estado oculto\n",
        "\n",
        "        # Operación lineal\n",
        "        z_t = w_hh @ h_t_prev+w_xh @ x_t+b_h\n",
        "\n",
        "        # Activación\n",
        "        h_t = sigmoid(z_t)\n",
        "\n",
        "        ### ACABA CODIGO ###\n",
        "\n",
        "        return h_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxvgjcArnOOW"
      },
      "source": [
        "Vamos a probar como funciona"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lkNTe0QhnOOW",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Valor h_t:\n",
            "[[0.00456287]\n",
            " [0.78784736]] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Data\n",
        "\n",
        "nh = 2   # Dimensión del vector de variables ocultas\n",
        "nx = 3   # Dimensión del vector de entrada\n",
        "\n",
        "#w_hh = np.full((nh, nh), 1.)  # 3x2 llenado con puros 1s\n",
        "#w_hx = np.full((nh, nx), 9.)  # 3x3 llenado con puros 9s\n",
        "#h_t_prev = np.full((nh, 1), 1.)  # 2x1 llenado con puros 1s\n",
        "#x_t = np.full((nx, 1), 9.)       # 3x1 llenado con puros 9s\n",
        "b_h = np.zeros((nh, 1))\n",
        "\n",
        "# Si prefieres valores aleatorios, descomenta lo siguiente:\n",
        "\n",
        "w_hh = np.random.standard_normal((nh,nh))\n",
        "w_hx = np.random.standard_normal((nh,nx))\n",
        "h_t_prev = np.random.standard_normal((nh,1))\n",
        "x_t = np.random.standard_normal((nx,1))\n",
        "\n",
        "# Aplicando un solo paso\n",
        "h_t = forward_V_RNN([x_t, h_t_prev], [w_hh, w_hx, b_h])\n",
        "\n",
        "print(\"\\nValor h_t:\")\n",
        "print(h_t, \"\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05Wd2v3gnOOX"
      },
      "source": [
        "## RNN tipo LSTM\n",
        "\n",
        "Una LST es un modelo como el que se muestra en la figura, con todo y sus ecuaciones\n",
        "\n",
        "![](https://github.com/mcd-unison/aaa-curso/blob/main/ejemplos/LSTM.png?raw=1)\n",
        "\n",
        "![](https://github.com/mcd-unison/aaa-curso/blob/main/ejemplos/LSTMeq.png?raw=1)\n",
        "\n",
        "Como podemos ver tenemos 3 vectores de entrada a la celda:\n",
        "\n",
        "- $h^{<t-1>}$ el vector de variables ocultas provenientes de un paso anterior,\n",
        "- $C^{<t-1>}$ el vector de valores de celda (memoria de largo plazo) provenientes de un paso anterior,\n",
        "- $x^{<t>}$ el vector de variables de entrada. Idealmente debería estar normalizado entre -1 y 1 cada uno de los valores de entrada.\n",
        "\n",
        "Como podemos ver tenemos varias operaciones:\n",
        "\n",
        "- Una compuerta de olvido $f$ que depende de $h^{<t-1>}$ y $x^{<t>}$ cuya salida es un vector del tamaño de las variables ocultas con valores entre 0 y 1 con la importancia que debe tener el valor de celda anterior (memoria de largo plazo)\n",
        "\n",
        "- Una compuerta de entrada $i$ que depende de $h^{<t-1>}$ y $x^{<t>}$ cuya salida es un vector del tamaño de las variables ocultas con valores entre 0 y 1 con la importancia que debe tener la activación de la celda actual (memoria de corto plazo)\n",
        "\n",
        "- Una compuerta de salida $i$ que depende de $h^{<t-1>}$ y $x^{<t>}$ cuya salida es un vector del tamaño de las variables ocultas con valores entre 0 y 1 con la importancia que debe tener el valor de celda actual en el valor de la de la variable oculta correspondiente.\n",
        "\n",
        "- El calculo de la activación actual, que depende de $h^{<t-1>}$ y $x^{<t>}$, el cual se hace con una tangente hiperbólica, para mantener los valores entre -1 y 1.\n",
        "\n",
        "\n",
        "Hagamos entonces una celda LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1-fG6JpRnOOY"
      },
      "outputs": [],
      "source": [
        "def forward_LSTM(inputs, weights):\n",
        "    # Forward propagation para una RNN tipo LSTM\n",
        "    x_t, h_t_prev, C_t_prev = inputs\n",
        "\n",
        "    # weights.\n",
        "    Ui, Wi, bi, Uf, Wf, bf, Uo, Wo, bo, U, W, b = weights\n",
        "\n",
        "    ### INICIA CODIGO ###\n",
        "    # Nuevo estado oculto y valor de celda\n",
        "\n",
        "    # Compuerta de entrada\n",
        "    i = sigmoid(Wi @ x_t + Ui @ h_t_prev + bi)\n",
        "\n",
        "    # Compuerta de olvido\n",
        "    f = sigmoid(Wf @ x_t + Uf @ h_t_prev + bf)\n",
        "\n",
        "    # Compuerta de salida\n",
        "    o = sigmoid(Wo @ x_t + Uo @ h_t_prev + bo)\n",
        "\n",
        "    # Valor de celda de memoria de corto plazo\n",
        "    C_t_short = np.tanh(W @ x_t + U @ h_t_prev + b)\n",
        "\n",
        "    # Valor de celda de memoria de corto y largo plazo\n",
        "    C_t = f * C_t_prev + i * C_t_short\n",
        "\n",
        "    # Valor de variable oculta\n",
        "    h_t = o * np.tanh(C_t)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return h_t, C_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al0VHLyVnOOY"
      },
      "source": [
        "Vamos a probar como funciona"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LWmtdUxKnOOZ"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "shapes (2,2) and (3,1) not aligned: 2 (dim 1) != 3 (dim 0)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m x_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mstandard_normal((nx,\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Aplicando un solo paso\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m h_t, C_t \u001b[38;5;241m=\u001b[39m \u001b[43mforward_LSTM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_t_prev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC_t_prev\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mUi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mUf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mUo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mValor h_t:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(h_t, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[15], line 12\u001b[0m, in \u001b[0;36mforward_LSTM\u001b[1;34m(inputs, weights)\u001b[0m\n\u001b[0;32m      6\u001b[0m Ui, Wi, bi, Uf, Wf, bf, Uo, Wo, bo, U, W, b \u001b[38;5;241m=\u001b[39m weights\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m### INICIA CODIGO ###\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Nuevo estado oculto y valor de celda\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Compuerta de entrada\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m i \u001b[38;5;241m=\u001b[39m sigmoid(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(Ui, h_t_prev) \u001b[38;5;241m+\u001b[39m bi)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Compuerta de olvido\u001b[39;00m\n\u001b[0;32m     15\u001b[0m f \u001b[38;5;241m=\u001b[39m sigmoid(Wf \u001b[38;5;241m@\u001b[39m x_t \u001b[38;5;241m+\u001b[39m Uf \u001b[38;5;241m@\u001b[39m h_t_prev \u001b[38;5;241m+\u001b[39m bf)\n",
            "\u001b[1;31mValueError\u001b[0m: shapes (2,2) and (3,1) not aligned: 2 (dim 1) != 3 (dim 0)"
          ]
        }
      ],
      "source": [
        "# Data\n",
        "\n",
        "nh = 2   # Dimensión del vector de variables ocultas\n",
        "nx = 3   # Dimensión del vector de entrada\n",
        "\n",
        "Ui = np.random.standard_normal((nh,nx))\n",
        "Wi = np.random.standard_normal((nh,nh))\n",
        "bi = np.random.standard_normal((nh,1))\n",
        "\n",
        "Uf = np.random.standard_normal((nh,nx))\n",
        "Wf = np.random.standard_normal((nh,nh))\n",
        "bf = np.random.standard_normal((nh,1))\n",
        "\n",
        "Uo = np.random.standard_normal((nh,nx))\n",
        "Wo = np.random.standard_normal((nh,nh))\n",
        "bo = np.random.standard_normal((nh,1))\n",
        "\n",
        "U = np.random.standard_normal((nh,nx))\n",
        "W = np.random.standard_normal((nh,nh))\n",
        "b = np.random.standard_normal((nh,1))\n",
        "\n",
        "h_t_prev = 2 * np.random.standard_normal((nh,1)) - 1\n",
        "C_t_prev = np.random.standard_normal((nh,1))\n",
        "x_t = 2 * np.random.standard_normal((nx,1)) - 1\n",
        "\n",
        "# Aplicando un solo paso\n",
        "h_t, C_t = forward_LSTM(\n",
        "    [x_t, h_t_prev, C_t_prev],\n",
        "    [Ui, Wi, bi, Uf, Wf, bf, Uo, Wo, bo, U, W, b]\n",
        ")\n",
        "\n",
        "print(\"\\nValor h_t:\")\n",
        "print(h_t, \"\\n\")\n",
        "\n",
        "print(\"\\nValor C_t:\")\n",
        "print(C_t, \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGBVpRlLnOOZ"
      },
      "source": [
        "## La función `scan`para el cálculo de BPTT\n",
        "\n",
        "La función `scan` se usa para calcular la propagación hacia adelante. Si la funcións e implementa en un *framework* como *Tensorflow* o *pytorch*, entonces se puede ir guardando los gradientes de cada aplicación a lo largo del tiempo y usarlos en el calculo del gradiente para la función de aprendizaje.\n",
        "\n",
        "Aquí solo vamos a tratar de mostrar como funcionaría dicha función, la cual recibe:\n",
        "\n",
        "- `elems` : lista de entradas (`X`)\n",
        "- `weights` : los parámetros que necesita la función de feedforward para su cálculo (pesos)\n",
        "- `h_0` : estado oculto inicial\n",
        "\n",
        "`scan` va por todos los valores de `x` en `elems`, llama la función de feedforward con los argumentos necesarios, guarda el estado oculto `h_t` y agrega el valor de `h_t` a una lista.\n",
        "\n",
        "Vamos a hacer la función de scan para una celda tipo RNN vainilla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DXvbxrWnOOa"
      },
      "outputs": [],
      "source": [
        "def scan_V_RNN(elems, weights, h_0=None): # Forward propagation for RNNs\n",
        "    h_t = h_0\n",
        "    h = []\n",
        "    for x in elems:\n",
        "        h_t = forward_V_RNN([x, h_t], weights)\n",
        "        h.append(h_t)\n",
        "    return h, h_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZh_0iICnOOa"
      },
      "source": [
        "Vamos a probar inicializando una posible red RNN vainilla en un probable pornblema de PLN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b87mPMu6nOOa"
      },
      "outputs": [],
      "source": [
        "np.random.seed(10)\n",
        "\n",
        "emb = 128                       # Embedding\n",
        "T = 256                         # Tamaño de secuencia de tokens\n",
        "h_dim = 16                      # Estados ocultos\n",
        "\n",
        "h_0 = np.zeros((h_dim, 1))      # Estado inicial\n",
        "\n",
        "# Inicialización aleatoria de pesos y sesgos\n",
        "Whh = np.random.standard_normal((h_dim, h_dim))\n",
        "Wxh = np.random.standard_normal((h_dim, emb))\n",
        "bh = np.random.standard_normal((h_dim, 1))\n",
        "\n",
        "# Inicialización aleatoria de una secuencia de tokens (en embeddings)\n",
        "X = np.random.standard_normal((T, emb, 1))\n",
        "\n",
        "weights = [Whh, Wxh, bh]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxYUScdtnOOa"
      },
      "outputs": [],
      "source": [
        "# vanilla RNNs\n",
        "tic = perf_counter()\n",
        "h, h_T = scan_V_RNN(X, weights, h_0)\n",
        "toc = perf_counter()\n",
        "RNN_time=(toc-tic)*1000\n",
        "print (f\"Tomó {RNN_time:.2f}ms ejecutar el método de RNN vainilla.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9YyM29xnOOb"
      },
      "source": [
        "**Desarrolla la función de scan para LSTM y prueba con la misma secuencia de entradas para una red LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1f1SI7SnOOb"
      },
      "outputs": [],
      "source": [
        "# Función scan para LSTM\n",
        "\n",
        "# INICIA CODIGO\n",
        "\n",
        "# TERMINA CODIGO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZ7560DZnOOb"
      },
      "outputs": [],
      "source": [
        "# Inicialización de variables\n",
        "\n",
        "# INICIA CODIGO\n",
        "\n",
        "# TERMINA CODIGO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53KiTx7GnOOb"
      },
      "outputs": [],
      "source": [
        "# Probando la función de scan\n",
        "\n",
        "# INICIA CODIGO\n",
        "\n",
        "# TERMINA CODIGO"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
